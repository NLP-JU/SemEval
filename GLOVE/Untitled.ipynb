{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "wordsList = np.load('wordList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_tweet1.csv   glove_use.ipynb  wordList.npy\r\n",
      "glove.6B.200d.txt  Untitled.ipynb   wordVectors.npy\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "(400000, 200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(wordsList))\n",
    "print(wordVectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.077024 ,  0.061414 , -1.0141   ,  0.25311  , -0.37057  ,\n",
       "        0.71021  , -0.55703  , -0.10114  ,  0.34124  , -0.70779  ,\n",
       "       -0.40961  , -0.19704  , -0.49629  , -0.32381  ,  1.005    ,\n",
       "       -0.2056   , -0.38367  ,  0.59779  ,  0.32359  ,  0.46351  ,\n",
       "        0.36828  ,  1.7844   , -0.2017   , -0.28919  ,  0.34601  ,\n",
       "        0.27598  , -0.010945 , -0.17085  , -0.12008  , -0.94413  ,\n",
       "        0.023241 ,  0.18633  , -0.36373  ,  0.3101   , -0.17338  ,\n",
       "       -0.42261  , -0.208    ,  0.3396   ,  0.70648  ,  0.29459  ,\n",
       "       -0.048501 , -0.48304  ,  0.9551   , -0.17855  , -0.32686  ,\n",
       "        0.40669  ,  0.60312  ,  0.089504 ,  0.02459  ,  0.22576  ,\n",
       "        0.059842 , -0.15595  , -0.028905 ,  0.13285  , -0.57957  ,\n",
       "        0.47502  ,  0.33218  , -0.030031 , -0.52208  ,  0.1205   ,\n",
       "        0.11466  , -0.063817 , -0.41687  , -0.13421  ,  0.042131 ,\n",
       "        0.063812 ,  0.60716  ,  0.043813 ,  1.2489   ,  0.82483  ,\n",
       "        1.1958   , -0.024125 ,  0.36323  ,  0.033399 , -0.708    ,\n",
       "        0.044144 ,  0.13927  ,  0.18314  ,  0.29395  , -0.056808 ,\n",
       "       -0.77934  , -0.06526  ,  0.56817  , -0.22374  , -0.46116  ,\n",
       "        0.46741  , -0.58674  ,  0.037338 ,  0.43748  , -0.5784   ,\n",
       "       -0.36445  , -0.38476  ,  0.39554  ,  0.12007  ,  0.54567  ,\n",
       "       -0.67141  ,  0.27453  ,  0.68984  , -0.20922  ,  0.087193 ,\n",
       "        0.12365  , -0.023204 , -0.58762  , -0.43715  ,  0.49447  ,\n",
       "       -0.55336  , -0.035771 ,  1.2779   , -0.54762  , -0.024569 ,\n",
       "        0.30538  , -0.46519  ,  0.34132  , -0.037047 , -0.69803  ,\n",
       "        0.50185  , -0.37162  ,  0.24227  , -0.335    , -0.45742  ,\n",
       "        0.096741 ,  0.60727  , -0.24345  ,  0.89153  ,  0.45262  ,\n",
       "       -0.52468  ,  0.18471  , -0.38466  ,  0.0078941, -0.31441  ,\n",
       "        0.33166  , -0.21688  , -0.063286 ,  0.021742 , -0.062783 ,\n",
       "        0.96358  ,  0.18462  ,  0.22578  , -0.55583  ,  0.038211 ,\n",
       "        0.42008  ,  0.013877 ,  0.2027   ,  0.083203 ,  1.0075   ,\n",
       "        0.66971  ,  0.42355  , -0.45019  , -0.15676  ,  0.32855  ,\n",
       "        0.8405   , -0.46617  , -1.4334   , -0.44476  , -0.72146  ,\n",
       "       -0.073128 ,  0.13918  , -1.0442   ,  0.41261  , -0.36253  ,\n",
       "        0.86267  ,  0.82961  ,  0.20322  , -0.81048  , -0.19287  ,\n",
       "       -0.18585  ,  0.29162  ,  0.18769  , -0.58648  ,  0.31679  ,\n",
       "        0.078393 , -0.013512 ,  0.18804  ,  0.085978 ,  0.59671  ,\n",
       "       -0.36378  , -0.28311  ,  0.32205  , -0.58474  , -0.28672  ,\n",
       "        0.74337  , -0.0037654,  0.085396 , -0.15802  , -0.66172  ,\n",
       "       -0.06117  , -0.052406 ,  0.194    ,  0.12447  ,  0.30573  ,\n",
       "        0.30173  , -0.1307   ,  0.8188   ,  0.14053  , -0.12806  ,\n",
       "        0.6224   , -0.32647  ,  0.47737  ,  0.58362  ,  0.37044  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseballIndex = wordsList.index('baseball')\n",
    "wordVectors[baseballIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[   41   804     0  1005    15  7446     5 13767     0     0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "maxSeqLength = 10 #Maximum length of sentence\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"i\")\n",
    "firstSentence[1] = wordsList.index(\"thought\")\n",
    "firstSentence[2] = wordsList.index(\"the\")\n",
    "firstSentence[3] = wordsList.index(\"movie\")\n",
    "firstSentence[4] = wordsList.index(\"was\")\n",
    "firstSentence[5] = wordsList.index(\"incredible\")\n",
    "firstSentence[6] = wordsList.index(\"and\")\n",
    "firstSentence[7] = wordsList.index(\"inspiring\")\n",
    "#firstSentence[8] and firstSentence[9] are going to be 0\n",
    "print(firstSentence.shape)\n",
    "print(firstSentence) #Shows the row index for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,firstSentence).eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4400ebde5afa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordVectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfirstSentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m     \"\"\"\n\u001b[0;32m--> 711\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5139\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5141\u001b[0;31m       raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\n\u001b[0m\u001b[1;32m   5142\u001b[0m                        \u001b[0;34m\"session is registered. Use `with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5143\u001b[0m                        \u001b[0;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
     ]
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(wordVectors,firstSentence).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
